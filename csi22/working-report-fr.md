L’objectif de la thèse, pour rappel, est de concevoir un modèle de synthèse de mouvements 3D à partir d’une vidéo RGB. Nous visons à utiliser des techniques d’apprentissage profond pour résoudre cette problématique de reconstruction de mouvements sans marqueurs. Les avantages d'un tel système seraient de s’abstraire des contraintes liées à l’acquisition de mouvement classique (capture du mouvement à faible coût, pas d’équipement intrusif du sujet, pas de calibration du système).

Durant cette deuxième année, mes travaux se sont focalisés principalement sur la mise en place du modèle d'estimation de poses. Il existe dans la littérature de nombreuses approches capables de résoudre cette tâche. Cependant la plupart de ces dernières ne se focalisent pas sur l'aspect temporel du mouvement. Nous avons donc cherché à intégrer l'information temporelle dans le processus de mise en place du modèle, que ce soit par son architecture ou de la manière dont il est entraîné. Parmi les possibilités envisagées, on note :
* l'utilisation de la convolution 1D sur une séquence de poses 2D pour estimer une séquence de poses en 3D ;
* l'utilisation d'une phase de lissage temporelle après estimation de la séquence de poses en 3D. Cette phase peut être greffée à la suite d’un estimateur image à pose 3D ou séquence de poses 2D à séquence de poses 3D ;
* l'utilisation lors de l’entraînement d'une fonction de perte capable d'intégrer les caractéristiques temporelles dans le modèle lors de la rétro-propagation.

Nos premières expérimentations ont porté sur la première possibilité évoquée précédemment. Les premiers résultats de ces expérimentations ont été présenté lors des journées JFIG 2021. Ces premiers résultats ont permis de se faire une idée de l'approche scientifique à adopter dans la réalisation de nos objectifs. Nous avons utilisé une architecture simple de convolution 1D pour observer les résultats sur notre base de données établies au cours de la première année (base de données réduites, facile pour les tests rapides). Les résultats ont permis de montrer l'avantage de la convolution 1D sur la fluidité temporelle des mouvements estimés. Malheureusement cette simple architecture était insuffisante quant à la précision spatiale. Pour la suite nous avons cherché à améliorer l'architecture afin d'obtenir de meilleurs résultats spatiaux.

Dans cette seconde vague d'expérimentations, nous avons travaillé sur les différents paramètres du d'architecture et d'entraînement du modèle (taille des filtres, dilatation, nombre de canaux de convolution...). La plus intéressante découverte dans cette phase est la découverte d'une fonction de perte "Motion Loss" et la mise en place d'une fonction de perte basée sur la représentation Laplacienne du mouvement. Ces deux fonctions apportent une amélioration des résultats dans l’entraînement des résultats. Nous avons également pensé à une fonction de perte qui permet d'évaluer la qualité temporelle des résultats. Des comparaisons ont été faites avec le modèle MotioNet suivant le "Protocole#1" de la base de données Human3.6m.

En parallèle à ces expérimentations, nous avons entamé les préparatifs pour la mise en place d'une base de données de mouvements de personnes en situation de handicap en collaboration avec le centre Kerpape de Lorient.

Nous envisageons poursuivre les travaux sur la mise en place du modèle en incluant la deuxième option (lissage temporelle). Le meilleur modèle obtenu pourra être évalué sur la base de données handicap que nous mettrons en place.

En termes de publication, nous visons Motion In Game ou CASA.
